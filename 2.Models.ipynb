{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import Normalize, Resize, ToTensor\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from XrayDataset import XrayDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'checkpoint2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/lusnlsas/ramkik_data/covid19/covid/logs/resnet_last'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = \"resnet_full\"\n",
    "\n",
    "os.path.join(os.getcwd(), 'logs', log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf_writer = SummaryWriter(os.path.join(os.getcwd(), 'logs', log))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rootfolders():\n",
    "    \"\"\"Create log and model folder\"\"\"\n",
    "    folders_util = [checkpoint]\n",
    "    for folder in folders_util:\n",
    "        if not os.path.exists(folder):\n",
    "            print('creating folder ' + folder)\n",
    "            os.mkdir(folder)\n",
    "\n",
    "check_rootfolders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(epoch , state):\n",
    "    filename = '%s/ckpt-%s.pth.tar' % (checkpoint, epoch)\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Sequential(nn.Linear(2048, 512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(512, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.to(device)\n",
    "if torch.cuda.is_available():\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
    "else:\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1038</td>\n",
       "      <td>0c2e9b99-9a8f-4b44-854e-acd181a0208c.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2922</td>\n",
       "      <td>34fdff09-5bc2-4df5-b8cf-3c37662037c8.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1174</td>\n",
       "      <td>0ebc8268-df3d-45d8-8ee7-b34880c62830.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>341</td>\n",
       "      <td>06f1d0a2-d8c5-4229-9944-59da85c96b81.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>280</td>\n",
       "      <td>06951c33-b247-4daf-a087-cc082f83238b.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>1200</td>\n",
       "      <td>0f8c91da-7e03-480e-8760-1604b1d53c97.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>1151</td>\n",
       "      <td>0dbb83c1-2214-4152-ac69-d1e7e25453cb.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>499</td>\n",
       "      <td>081e308c-0134-4ba3-b745-f632e37a83a1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>663</td>\n",
       "      <td>095d6b7c-fa53-4f06-90b9-5c5f76038f04.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>919</td>\n",
       "      <td>0b6a7730-a747-42ce-ac00-f3dcc34df307.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>945 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                  filename  label\n",
       "0          1038  0c2e9b99-9a8f-4b44-854e-acd181a0208c.jpg      0\n",
       "1          2922  34fdff09-5bc2-4df5-b8cf-3c37662037c8.jpg      2\n",
       "2          1174  0ebc8268-df3d-45d8-8ee7-b34880c62830.jpg      2\n",
       "3           341  06f1d0a2-d8c5-4229-9944-59da85c96b81.jpg      0\n",
       "4           280  06951c33-b247-4daf-a087-cc082f83238b.jpg      0\n",
       "..          ...                                       ...    ...\n",
       "940        1200  0f8c91da-7e03-480e-8760-1604b1d53c97.jpg      0\n",
       "941        1151  0dbb83c1-2214-4152-ac69-d1e7e25453cb.jpg      0\n",
       "942         499  081e308c-0134-4ba3-b745-f632e37a83a1.jpg      0\n",
       "943         663  095d6b7c-fa53-4f06-90b9-5c5f76038f04.jpg      2\n",
       "944         919  0b6a7730-a747-42ce-ac00-f3dcc34df307.jpg      0\n",
       "\n",
       "[945 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(os.getcwd(), 'data', 'train.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0c2e9b99-9a8f-4b44-854e-acd181a0208c.jpg'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "945"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "945"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                                     #transforms.Grayscale(1),\n",
    "                                      # transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "                                        transforms.RandomRotation(30),\n",
    "                                        transforms.ColorJitter(brightness=0.6, contrast=0.6),\n",
    "                                        transforms.RandomVerticalFlip(p=0.4),\n",
    "    \n",
    "                                        transforms.RandomHorizontalFlip(p=0.4),\n",
    "                                        transforms.Resize((224,224)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "                                       ])\n",
    "test_transforms = transforms.Compose([\n",
    "#                                     transforms.Grayscale(1),\n",
    "                                      transforms.Resize((224,224)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = XrayDataset( 'data', 'train', 'train.csv', train_transforms )\n",
    "\n",
    "test_dataset = XrayDataset('data', 'test', 'test.csv', test_transforms )\n",
    "\n",
    "image, label = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size,  shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size,  shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    start_val_time = time.time()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    count_loop = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                input = input.cuda()\n",
    "                target = target.cuda()\n",
    "                \n",
    "            count_loop +=1\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    accurecy = 100 * correct / total\n",
    "    end_val_time = time.time()\n",
    "\n",
    "    currentDT = datetime.datetime.now()        \n",
    "    print(str(currentDT), \"=== Validation Loss : \", running_loss, \"  Accurecy : \", accurecy, \"count loop : \", count_loop, \"   Validation Time :  \", (end_val_time-start_val_time) )\n",
    "    \n",
    "    if tf_writer is not None:\n",
    "        tf_writer.add_scalar('accurecy/test', accurecy, epoch)\n",
    "        tf_writer.add_scalar('loss/test', running_loss, epoch)\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1500\n",
    "steps = 0\n",
    "print_every = 1\n",
    "  \n",
    "train_losses, test_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " === epoch :  0 === Training Loss :  4.11290967464447   Accurecy :  41.58730158730159\n",
      "2020-04-18 14:06:25.775377 === Validation Loss :  1.0180511474609375   Accurecy :  44.76190476190476 count loop :  1    Validation Time :   3.401064872741699\n",
      " === epoch :  1 === Training Loss :  3.976257026195526   Accurecy :  44.44444444444444\n",
      "2020-04-18 14:06:43.860528 === Validation Loss :  0.972497284412384   Accurecy :  42.857142857142854 count loop :  1    Validation Time :   2.8869292736053467\n",
      " === epoch :  2 === Training Loss :  3.825497031211853   Accurecy :  51.851851851851855\n",
      "2020-04-18 14:07:03.508462 === Validation Loss :  0.9403285980224609   Accurecy :  57.142857142857146 count loop :  1    Validation Time :   2.8315787315368652\n",
      " === epoch :  3 === Training Loss :  3.7605040073394775   Accurecy :  53.01587301587302\n",
      "2020-04-18 14:07:21.408995 === Validation Loss :  0.9488921165466309   Accurecy :  48.57142857142857 count loop :  1    Validation Time :   3.01950740814209\n",
      " === epoch :  4 === Training Loss :  3.630917251110077   Accurecy :  55.97883597883598\n",
      "2020-04-18 14:07:39.788091 === Validation Loss :  0.907849133014679   Accurecy :  60.0 count loop :  1    Validation Time :   2.941490650177002\n",
      " === epoch :  5 === Training Loss :  3.5815484523773193   Accurecy :  59.15343915343915\n",
      "2020-04-18 14:07:58.289528 === Validation Loss :  0.908968985080719   Accurecy :  47.61904761904762 count loop :  1    Validation Time :   2.8597514629364014\n",
      " === epoch :  6 === Training Loss :  3.515625774860382   Accurecy :  58.51851851851852\n",
      "2020-04-18 14:08:16.055605 === Validation Loss :  0.8881411552429199   Accurecy :  61.904761904761905 count loop :  1    Validation Time :   2.8856658935546875\n",
      " === epoch :  7 === Training Loss :  3.386776328086853   Accurecy :  60.74074074074074\n",
      "2020-04-18 14:08:34.759811 === Validation Loss :  0.8845351338386536   Accurecy :  51.42857142857143 count loop :  1    Validation Time :   2.8833439350128174\n",
      " === epoch :  8 === Training Loss :  3.358126401901245   Accurecy :  60.423280423280424\n",
      "2020-04-18 14:08:52.628673 === Validation Loss :  0.8698601126670837   Accurecy :  61.904761904761905 count loop :  1    Validation Time :   2.956023693084717\n",
      " === epoch :  9 === Training Loss :  3.3501139283180237   Accurecy :  59.576719576719576\n",
      "2020-04-18 14:09:12.013598 === Validation Loss :  0.8704884052276611   Accurecy :  55.23809523809524 count loop :  1    Validation Time :   2.9267497062683105\n",
      " === epoch :  10 === Training Loss :  3.2978386282920837   Accurecy :  62.96296296296296\n",
      "2020-04-18 14:09:29.898565 === Validation Loss :  0.8661489486694336   Accurecy :  53.333333333333336 count loop :  1    Validation Time :   3.0680758953094482\n",
      " === epoch :  11 === Training Loss :  3.3102301359176636   Accurecy :  60.10582010582011\n",
      "2020-04-18 14:09:47.735350 === Validation Loss :  0.8498241901397705   Accurecy :  60.95238095238095 count loop :  1    Validation Time :   2.8963818550109863\n",
      " === epoch :  12 === Training Loss :  3.229353904724121   Accurecy :  62.01058201058201\n",
      "2020-04-18 14:10:06.639866 === Validation Loss :  0.858120858669281   Accurecy :  51.42857142857143 count loop :  1    Validation Time :   3.0921237468719482\n",
      " === epoch :  13 === Training Loss :  3.20385605096817   Accurecy :  62.96296296296296\n",
      "2020-04-18 14:10:25.827132 === Validation Loss :  0.8403177857398987   Accurecy :  57.142857142857146 count loop :  1    Validation Time :   2.938084125518799\n",
      " === epoch :  14 === Training Loss :  3.204351007938385   Accurecy :  62.32804232804233\n",
      "2020-04-18 14:10:44.735818 === Validation Loss :  0.8356958031654358   Accurecy :  55.23809523809524 count loop :  1    Validation Time :   2.8838415145874023\n",
      " === epoch :  15 === Training Loss :  3.1744094491004944   Accurecy :  62.116402116402114\n",
      "2020-04-18 14:11:02.222936 === Validation Loss :  0.8111389875411987   Accurecy :  59.04761904761905 count loop :  1    Validation Time :   2.999277353286743\n",
      " === epoch :  16 === Training Loss :  3.2004834413528442   Accurecy :  62.96296296296296\n",
      "2020-04-18 14:11:20.020639 === Validation Loss :  0.8433929681777954   Accurecy :  58.095238095238095 count loop :  1    Validation Time :   2.8714869022369385\n",
      " === epoch :  17 === Training Loss :  3.065218150615692   Accurecy :  63.91534391534392\n",
      "2020-04-18 14:11:38.811814 === Validation Loss :  0.7814314365386963   Accurecy :  63.80952380952381 count loop :  1    Validation Time :   2.861281156539917\n",
      " === epoch :  18 === Training Loss :  3.0632722973823547   Accurecy :  65.18518518518519\n",
      "2020-04-18 14:11:56.542635 === Validation Loss :  0.7966651320457458   Accurecy :  60.0 count loop :  1    Validation Time :   2.884188413619995\n",
      " === epoch :  19 === Training Loss :  3.0193711519241333   Accurecy :  64.65608465608466\n",
      "2020-04-18 14:12:14.317061 === Validation Loss :  0.774501621723175   Accurecy :  61.904761904761905 count loop :  1    Validation Time :   2.857764720916748\n",
      " === epoch :  20 === Training Loss :  3.0416102409362793   Accurecy :  64.33862433862434\n",
      "2020-04-18 14:12:32.334305 === Validation Loss :  0.7746841311454773   Accurecy :  62.857142857142854 count loop :  1    Validation Time :   2.846120595932007\n",
      " === epoch :  21 === Training Loss :  2.961266338825226   Accurecy :  65.39682539682539\n",
      "2020-04-18 14:12:50.869588 === Validation Loss :  0.7589991092681885   Accurecy :  64.76190476190476 count loop :  1    Validation Time :   2.8901829719543457\n",
      " === epoch :  22 === Training Loss :  2.976729154586792   Accurecy :  65.39682539682539\n",
      "2020-04-18 14:13:08.524131 === Validation Loss :  0.7508196234703064   Accurecy :  64.76190476190476 count loop :  1    Validation Time :   2.8874566555023193\n",
      " === epoch :  23 === Training Loss :  2.983104944229126   Accurecy :  66.45502645502646\n",
      "2020-04-18 14:13:26.067371 === Validation Loss :  0.7253297567367554   Accurecy :  65.71428571428571 count loop :  1    Validation Time :   2.8761777877807617\n",
      " === epoch :  24 === Training Loss :  2.9797788858413696   Accurecy :  65.18518518518519\n",
      "2020-04-18 14:13:44.054058 === Validation Loss :  0.7261717319488525   Accurecy :  65.71428571428571 count loop :  1    Validation Time :   2.9130430221557617\n",
      " === epoch :  25 === Training Loss :  2.913777470588684   Accurecy :  67.83068783068784\n",
      "2020-04-18 14:14:02.403297 === Validation Loss :  0.7198094129562378   Accurecy :  63.80952380952381 count loop :  1    Validation Time :   2.8951547145843506\n",
      " === epoch :  26 === Training Loss :  2.8977566361427307   Accurecy :  66.87830687830687\n",
      "2020-04-18 14:14:20.366664 === Validation Loss :  0.699629545211792   Accurecy :  64.76190476190476 count loop :  1    Validation Time :   2.8904576301574707\n",
      " === epoch :  27 === Training Loss :  2.9452914595603943   Accurecy :  65.71428571428571\n",
      "2020-04-18 14:14:39.193510 === Validation Loss :  0.7195472121238708   Accurecy :  65.71428571428571 count loop :  1    Validation Time :   3.200575590133667\n",
      " === epoch :  28 === Training Loss :  2.9301339387893677   Accurecy :  67.61904761904762\n",
      "2020-04-18 14:14:57.031634 === Validation Loss :  0.7293601036071777   Accurecy :  63.80952380952381 count loop :  1    Validation Time :   2.8513174057006836\n",
      " === epoch :  29 === Training Loss :  2.913802444934845   Accurecy :  67.19576719576719\n",
      "2020-04-18 14:15:14.842008 === Validation Loss :  0.6923035383224487   Accurecy :  65.71428571428571 count loop :  1    Validation Time :   2.869966983795166\n",
      " === epoch :  30 === Training Loss :  2.8841400146484375   Accurecy :  67.51322751322752\n",
      "2020-04-18 14:15:33.263216 === Validation Loss :  0.7418894171714783   Accurecy :  62.857142857142854 count loop :  1    Validation Time :   2.9645304679870605\n",
      " === epoch :  31 === Training Loss :  2.9239270091056824   Accurecy :  66.13756613756614\n",
      "2020-04-18 14:15:51.129181 === Validation Loss :  0.699315071105957   Accurecy :  65.71428571428571 count loop :  1    Validation Time :   2.8412423133850098\n",
      " === epoch :  32 === Training Loss :  2.8453508615493774   Accurecy :  68.57142857142857\n",
      "2020-04-18 14:16:10.741331 === Validation Loss :  0.6921380758285522   Accurecy :  64.76190476190476 count loop :  1    Validation Time :   2.9329428672790527\n",
      " === epoch :  33 === Training Loss :  2.7807405591011047   Accurecy :  69.1005291005291\n",
      "2020-04-18 14:16:28.857910 === Validation Loss :  0.7187185883522034   Accurecy :  65.71428571428571 count loop :  1    Validation Time :   2.9461207389831543\n",
      " === epoch :  34 === Training Loss :  2.856993317604065   Accurecy :  67.19576719576719\n",
      "2020-04-18 14:16:46.419132 === Validation Loss :  0.6697653532028198   Accurecy :  65.71428571428571 count loop :  1    Validation Time :   2.9031269550323486\n",
      " === epoch :  35 === Training Loss :  2.7754977345466614   Accurecy :  70.47619047619048\n",
      "2020-04-18 14:17:03.382311 === Validation Loss :  0.7009658813476562   Accurecy :  64.76190476190476 count loop :  1    Validation Time :   2.909696102142334\n",
      " === epoch :  36 === Training Loss :  2.774896025657654   Accurecy :  66.98412698412699\n",
      "2020-04-18 14:17:21.413201 === Validation Loss :  0.6701078414916992   Accurecy :  68.57142857142857 count loop :  1    Validation Time :   2.920069456100464\n",
      " === epoch :  37 === Training Loss :  2.812880516052246   Accurecy :  69.73544973544973\n",
      "2020-04-18 14:17:40.270822 === Validation Loss :  0.6974675059318542   Accurecy :  64.76190476190476 count loop :  1    Validation Time :   2.895153045654297\n",
      " === epoch :  38 === Training Loss :  2.7586737871170044   Accurecy :  68.46560846560847\n",
      "2020-04-18 14:17:59.163956 === Validation Loss :  0.6688262820243835   Accurecy :  64.76190476190476 count loop :  1    Validation Time :   2.9189367294311523\n",
      " === epoch :  39 === Training Loss :  2.7825010418891907   Accurecy :  68.78306878306879\n",
      "2020-04-18 14:18:17.633710 === Validation Loss :  0.670157790184021   Accurecy :  67.61904761904762 count loop :  1    Validation Time :   2.9870786666870117\n",
      " === epoch :  40 === Training Loss :  2.7442033290863037   Accurecy :  69.73544973544973\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    running_loss = 0.0     \n",
    "    correct = 0\n",
    "    total = 0 \n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for inputs, labels in train_dataloader:\n",
    "        steps += 1\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        logps = model(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(logps.data, 1)\n",
    "        #print(predicted)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        #print(correct)\n",
    "    \n",
    "    accurecy = 100 * correct / total\n",
    "    tf_writer.add_scalar('loss/train', running_loss, epoch)\n",
    "    tf_writer.add_scalar('accurecy/train', accurecy, epoch)\n",
    "    print( \" === epoch : \", epoch, \"=== Training Loss : \", running_loss, \"  Accurecy : \", accurecy )\n",
    "\n",
    "    validate(test_dataloader, model, criterion, epoch)\n",
    "    tf_writer.flush()\n",
    "    \n",
    "    \n",
    "    save_checkpoint(epoch, {\n",
    "                'epoch': epoch + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                \n",
    "            })\n",
    "\n",
    "tf_writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
